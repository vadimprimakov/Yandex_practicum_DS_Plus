# Поиск референсных фотографий для фотографов

Описание проекта

Вы работаете в фотохостинге для профессиональных фотографов «Со Смыслом» (“With Sense”). 
Ваши пользователи размещают свои фотографии на хостинге и сопровождают их полным описанием: указывают место съёмок, модель камеры и т. д. Отличительная особенность сервиса — описание: его может предоставить не только тот, кто размещает фотографию, но и другие пользователи портала. Например, для этой фотографии

![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_example_1.jpeg)

описание выглядит так:
⎢ A hiker poses for a picture in front of stunning mountains and clouds. 
Ваш отдел занимается экспериментом по разработке поиска референсных фотографий для фотографов. Суть поиска заключается в следующем: пользователь сервиса вводит описание нужной сцены. Например, такое:
⎢ A man is crossing a mountain pass on a metal bridge.
Сервис выводит несколько фотографий с такой же или похожей сценой.

![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_example_2.jpeg)

Чтобы эксперимент получил право на жизнь, нужно защитить его перед руководителем компании. Для защиты необходимо презентовать так называемый PoC (Proof of Concept, Проверка концепции) — продемонстрировать, что такой проект практически осуществим. Вам поручено разработать демонстрационную версию поиска изображений по запросу.
Для демонстрационной версии нужно выбрать лучшую  модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — и покажет, насколько текст и картинка подходят друг другу. 
На основе лучшей модели можно будет собрать предварительную версию продукта, которую вы покажете руководителю компании.

**Юридические ограничения**

В некоторых странах, где работает компания With Sense, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно, текстов, изображений, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16-ти лет.
В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:
⎢ This image is unavailable in your country in compliance with local laws.
Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому необходимо очистить данные от проблемного контента. Во время тестирования модели при появлении в запросе “вредного” контента должен отображаться дисклеймер. 

**Описание данных**
В файле train_dataset.csv находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат <имя файла изображения>#<порядковый номер описания>.

В папке train_images содержатся изображения для тренировки модели.

В файле CrowdAnnotations.tsv  — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:
- Имя файла изображения.
- Идентификатор описания.
- Доля людей, подтвердивших, что описание соответствует изображению.
- Количество человек, подтвердивших, что описание соответствует изображению.
- Количество человек, подтвердивших, что описание не соответствует изображению.

В файле ExpertAnnotations.tsv  — данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:
- Имя файла изображения.
- Идентификатор описания.
- 3, 4, 5 — оценки трёх экспертов. 

Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.      
В файле test_queries.csv находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат <имя файла изображения>#<порядковый номер описания>.

В папке test_images содержатся изображения для тестирования модели.
При решении задачи используйте только фреймворк Pytorch.

Инструкция по выполнению проекта

1. Шаг 1. Загрузите данные и проведите исследовательский анализ данных
Скачайте и откройте файлы с данными. Проверьте данные и откорректируйте их, если потребуется.
    - Напечатайте на экране 10–15 фотографий и посмотрите, как устроен датасет.
2. Шаг 2. Подготовьте данные к обучению модели
    - Создайте список слов которые, по вашему мнению, могут попадать под юридические ограничения.
    - Исключите из обучающего датасета пары, которые, исходя из подготовленного вами списка слов, могут попадать под юридические ограничения.
    - Сделайте векторизацию текстового описания методом BERT.
    - Сделайте векторизацию изображений с использованием модели ResNet18 из библиотеки Keras или PyTorch.
    - Дайте описание получившихся пар векторов с точки зрения их размерностей.
3. Обучите модель
- Создайте модель, которая покажет близость двух векторов. Модель должна принимать на вход конкатенированный вектор, состоящий из векторов описания и изображений, и предсказывать итоговую оценку экспертов.
- Выберите метрику, по которой вы будете сравнивать точность различных моделей.
- Обучите несколько моделей и подберите их гиперпараметры. В качестве моделей обязательно нужно рассмотреть:
    - 1. Линейную регрессию;
    - 2. Полносвязные нейронные сети.
4. Тестирование модели и демонстрация ее работы
- Проведите тестирование лучшей модели на тестовых данных.
- Напишите функцию, которая принимает на вход текстовое описание, делает его векторизацию и возвращает картинку с максимальным значением метрики.
(💡 Если запрос ведёт на юридически вредный контент, функция должна выводить дисклеймер.)
- С помощью написанной вами функции протестируйте работу модели на нескольких текстовых описаниях: проверьте, какие картинки она выдает при различных текстовых запросах.
5. Сделайте общий вывод по работе
Опишите модель, которая лучше всего справляется с задачей сравнения сходства картинки и текста. Опишите, какие ошибки допускает модель во время поиска картинки по её текстовому описанию. Оцените, насколько проект по созданию сервиса поиска фотографий по текстовому описанию практически осуществим.    

Содержание

1.  Исследовательский анализ данных
    - 1.1  Загрузка библиотек
    - 1.2  Загрузка датасетов
2.  Агрегация оценок
3.  Проверка данных
4.  Векторизация изображения
5.  Векторизация текстов
6.  Объединение векторов
7.  Обучение модели предсказания соответсвия
    - 7.1  LinearRegression
    - 7.2  LinearSVR
    - 7.3  Полносвязная нейронная сеть
8.  Тестирование модели
9.  Заключение, выводы, рекомендации 


## Цель исследования:

Собрать предварительную версию продукта, которую вы покажете руководителю компании. Во время тестирования модели при появлении в запросе “вредного” контента должен отображаться дисклеймер из-за юридических ограничений. Модель, должна показывать близость двух векторов, принимая на вход конкатенированный вектор, состоящий из векторов описания и изображений, и предсказывать итоговую оценку экспертов. Для демонстрационной версии нужно выбрать лучшую модель, которая получит векторное представление изображения, векторное представление текста.


## Ход исследования:

Шаг 1. Мы загрузили и ознакомились с данными. В нашем распоряжении оказалось 1000 обучающих картинок и 100 тестовых. Есть предобработанные файлы с сочетаниями описаний и картинок, для обучения и теста.

Для обучения доступны как экспертные оценки соответствия 5822 шт, так и оценки выполненные на краудфайдинговой платформе обычными людьми - 47830 шт, они частично совпадают.

Пересечений между наборами данных для обучения и теста не обнаружено. На обучающей выборке использованы только описания картинок под номером №2, в тесте к каждой картинке даны по 5 описаний.

Шаг 2. После анализа экспертных и краудсорсинговых оценок выбрана либо одна из них, либо объедина их в одну по критерию: оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.
Так как наша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.
Для этого была написана функция для агрегации оценок экспертов и применена к набору данных. Если все оценки разные - будем усреднять оценку и приводить к диапазону [0,1], если есть несколько одинаковых оценок - проголосуем большинством.

После добавления текстов, оказалось что для части `query_id` нет описаний, поэтому их было решено отбросить. Выбрали метод и аггрегировали оценки. Объединили оценки с обучающим набором данных, заполнили пропуски, удалили пропуски.

Шаг 3. Но наша задача убрать изображения, содержащие детей. Воспользуемся следующим способом. Он основан на том, что `query_id` содержит в с себе имя изображения, для которого он был написан.
    
 - Определить список плохих комментариев
 - У `query_id`  плохих комментариев отрезать два последних символа и получить список плохих изображений.

Применив данный способ мы верно определили список плохих комментариев. Фото с детьми не попадут в итоговый набор данных. Удалено 14496 изображений.
Мы проверили данные и исключили из обучения все изображения содержащие запрещённую информацию. 

Шаг 4. Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют "выделить" главные компоненты изображений. Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet. Тем самым мы получили векторизированные картинки

Шаг 5. Загрузив трансформер BERT base uncased преобразуем наши тексты. В итоге мы получили векторные представления для описаний текстов с помощью BERT

Шаг 6. Подготовим данные для обучения: объединим векторы изображений и векторы текстов с целевой переменной. Получены вектора комбинаций изображение-запрос при помощи предобученной сети архитектуры ResNet18 для изображений и BERT для текстов. Размерность полученного вектора составляет 512 + 768 = 1280. Обычно при создании сети мы определяем входящую размерность, но она не определяет количество неронов. Можно использовать сеть вообще из одного нейрона, при этом размерность вектора признаков будет 1280.

Шаг 7. Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки. Для того чтобы учесть изображения при разбиении, можно воспользоваться классом GroupShuffleSplit из библиотеки sklearn.model_selection. Благодаря использованию GroupShuffleSplit исключаем попадание одного изображения в обучающий и валидационный наборы.

Шаг 8. Обучение моделей

В качестве baseline'а попробовали модель линейной регрессии. Среднеквадратичная ошибка - 0.299

![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_lr.png)

Попробовали модель на основе метода опорных векторов. Среднеквадратичная ошибка - 0.242

![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_svr.png)

И наконец полносвязная нейронная сеть. Среднеквадратичная ошибка - 0.133

![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_nn_metrics.png)
![Пример фотографии](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_nn.png)

Шаг 9. Настало время протестировать модель. Для этого получили эмбеддинги для всех тестовых изображений из папки test_images, выбрали случайные 10 запросов из файла test_queries.csv и для каждого запроса вывели наиболее релевантное изображение.

## Итог исследования:

В данной работе мы делали прототип для системы поиска изображений по фотографии.

В ходе работы для векторизации изображений мы использовали сеть ResNet18, а для текстовых эмбеддингов BERT base uncased.

После объединения признаков и выделения целей (экспертные оценки схожести описания и картинок), мы исследовали три модели для оценки схожести:

   * LinearRegression
   * LinearSVR
   * полносвязную нейронную сеть

Лучше всего себя показала нейронная сеть, с ней мы провели тесты.

В конце работы мы написали функцию которая по тексту возвращает 5 наиболее похожих картинок и протестировали её на предложенном наборе тестовых картинок.

Модель работает не так как хотелось бы, в большинстве случаев в топ выдачи попадает неверные картинки. 

![Результат вывода модели на экран](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/20_search_photos/20_test.png)

Модель полносвязной нейронной сети за 250 эпох обучения уменьшила MAE с 18 до 12 на тренировочной выборке. На тестовой выборке результат составил 13.

Параметры обучения модели:

- Размер батча: 16 (batch_size=16 в функциях загрузки данных)
- Оптимизатор: Adam с learning rate = 0.000001
- Количество эпох: 250 (параметр epochs в функции train_model)

Основываясь на результатах работы модели, трудно с уверенностью сказать, произошло ли переобучение или нет. Однако, можно сделать обоснованное предположение о том, что более перспективным было бы привести ембеддинги изображений и текстов к одной размерности в одно пространство (через обучаемые слои) и в качестве меры близости использовать косинусное расстояние. 

## Стек технологий:

`pandas`, `matplotlib`, `numpy`, `seaborn`, `nltk`, `ResNet18`, `torch`, `torchvision`, `GroupShuffleSplit`

## Статус проекта:

Завершен.
