# Прогнозирование температуры звезды

Задача от обсерватории «Небо на ладони»: придумать, как с помощью нейросети определять температуру на поверхности обнаруженных звёзд. 

Обычно для расчёта температуры учёные пользуются следующими методами:
- Закон смещения Вина.
- Закон Стефана-Больцмана.
- Спектральный анализ.

Каждый из них имеет плюсы и минусы. Обсерватория хочет внедрить технологии машинного обучения для предсказания температуры звёзд, надеясь, что этот метод будет наиболее точным и удобным.
В базе обсерватории есть характеристики уже изученных 240 звёзд.

Характеристики
- Относительная светимость L/Lo — светимость звезды относительно Солнца.
- Относительный радиус R/Ro — радиус звезды относительно радиуса Солнца.
- Абсолютная звёздная величина Mv — физическая величина, характеризующая блеск звезды.
- Звёздный цвет (white, red, blue, yellow, yellow-orange и др.) — цвет звезды, который определяют на основе спектрального анализа.
- Тип звезды - 
    * Коричневый карлик - 0
    * Красный карлик - 1
    * Белый карлик - 2
    * Звёзды главной последовательности - 3
    * Сверхгигант	- 4
    * Гипергигант	- 5.
- Абсолютная температура T(K) — температура на поверхности звезды в Кельвинах.

В этом самостоятельном проекте вам необходимо разработать нейронную сеть, которая поможет предсказывать абсолютную температуру на поверхности звезды.


## Цель исследования:

Построение модели нейронной сети, которая поможет предсказывать абсолютную температуру на поверхности звезды, для оценки качества моделей будет применяться метрика RMSE, ее значение должно быть меньше 4500. Список параметров для перебора должен включать как минимум «dropout» и «размер батча».

## Ход исследования:

Шаг 1. Загрузка исходных данных из файла

Шаг 2. Исследовательский анализ
Проведен исследовательский анализ, используя графический анализ:
- количественных данных,
- категориальных данных.
Temperature (K) - температура на поверхности звезды находится в пределах от 2000 градусов (красные звёзды) до 40000 градусов (голубые звезды).
Luminosity(L/Lo) - относительная светимость относительно Солнца достигает 179432 при среднем значении 107188.
Также в данных характеристиках очень большой разброс значений


Шаг 3. Подготовка данных к построению модели
1. По результату исследовательского анализа внесены корректировки.
2. Категоризированы исходные данные.
3. Подготовлена обучающая и тестовая выборки.
4. Проведено масштабирование количественных данных.

Цвет звезд представлен несбалансировано, в данных преобладают красные, голубые и бело-голубые звезды, скрытые дубликаты исправлены.
С увеличением температуры начинает уменьшаться абсолютная звёздная величина.
При помощи радиуса можно выделить тип звезды.
Хорошо выделяются кластеры типа звезды в зависимости абсолютной звёздой величины.
Среди признаков замечена мультикорреляция между столбцом Star type и Absolute magnitude(Mv) равная 92%, но удаление одного из данных признаков не представляется возможным, так как они имеют большую статистическую значимость равную 21,63. 

Рассмотрим взаимосвязи температуры звезд с признаками:
- Star color - 74% корреляция. Одним из важнейших показателей температуры звезды является его цвет, скорее всего это вызвано приломлением светового луча, который доходит до нашей планеты.
- 'Absolute magnitude(Mv)' - 71% корреляция. Это физическая величина, характеризующая блеск астрономического объекта для наблюдателя, находящегося на некотором стандартном расстоянии от объекта. Использование абсолютной звёздной величины позволяет сравнивать действительную, а не наблюдаемую светимость объектов. Поэтому она очень схожа с понятием относительная светимость.
- Star type - 60% корреляция с таргетом. Всё просто у нас есть пять основных типов звёзд и по ним возможно понять их температуру, с точки зрения статистики и наблюдений.
- 'Luminosity(L/Lo)' - 56% корреляция. В любой статье можно наткнуться на слова о том, что главным фактором температуры звезды является его цвет, но фактически светимость звезды относительно Солнца позволяет нам понять насколько звезда теплая, хоть и не явно. 
- 'Radius(R/Ro)' - самая маленькая корреляция, равная всего 24%. Возможно это связано с природой, а точнее с плотностью и массой звёзд, ведь не важно какой объект будет по размерам, важнее из чего он состоит и каким цветом будет светить.

Шаг 4. Построение простой модели нейронной сети — baseline
1. Создан класс для задания архитектуры нейронной сети.
2. Самостоятельно выбрано количество скрытых слоёв, количество нейронов на них, функции активации на скрытых и выходном слоях. Проведено сравнение нескольких подобных комбинаций.
3. Проведено обучение нейронной сети:
    - Создана функцию для обучения нейронной сети.
    - Проведено обучение модели.
    - Построен график «Факт — Прогноз», где по горизонтальной оси отложены условные номера звёзд, а по вертикальной — температура в Кельвинах.
4. Сделан вывод.

Лучшая метрика получилась с оптимизацией методом адаптивной оценки моментов Adaptive Moment Estimation с шагом сходимости в 0.001 и до начала переобучения составила 6027.
Диагностируется переобучение, присутсвует ситуация при которой у модели высокая обобщающая способность на тренировочных данных, но она снижается на тестовых.
Согласно критериям заказчика, метрика RMSE не должна превышать 4500, требуется улучшение сети. Для этого попробуем использовать методы Batch Normalization и Dropout, а также подберем оптимальное количество эпох обучения. 
Нейронная сеть очень хорошо предсказывает температуру звёзд у которых температура до 5000 градусов. Но есть и критические расхождения.

Шаг 5. Улучшение сети
- Создано решение с перебором параметров нейросети. Список параметров для перебора должен включать как минимум «dropout» и «размер батча». Архитектуру нейронной сети: количество слоёв, нейронов, вид функции активации — оставьте как в Baseline, чтобы сравнить результат.
- Проведено обучение нейронной сети. Выведена метрика RMSE и график «Факт — прогноз». Метрика RMSE не должна превышать 4500.
- Сделан вывод. Желательно оформить его в виде таблицы или графика.

После проведенного перебора оптимизаторов - выявлено, что с данной задачей лучше всего справляется Adamax, lr: 0.01, не учитывая скорости алгоритмов, только по конечной RMSE.

На лучшем оптимитизаторе проведено конечное улучшение модели: добавили dropout равный 50% и регуляризацию весов BatchNorm1d на первый скрытый слой. На второй скрытый слой регуляризацию весов BatchNorm1d. Время обучения увеличилось, однако это способстовало улучшению метрики. 

Конечная метрика RMSE составила около 4000. Если посмотреть на график потерь нашей последней нейросети, то можно увидеть, что модель обучилась качественно, без недо- и переобучений, благодаря ранней остановке. График факт-прогноз похож на график базовой модели, однако можем увидеть, что начал предсказывать лучше до 15000 и свыше 30000 градусов по Кельвину, но стал хуже справляться со звездами до 5000 градусов.

![Потери нейросети](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/15_stars/15_loss.png)
![График "Факт-Прогноз" после улучшения сети](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/15_stars/15_final.png)

Шаг 6. Выводы по проекту
- Кратко описаны результаты каждого типа модели.
- Написаны выводы сравнения двух моделей.

## Итог исследования:

В ходе исследования была построеная базовая модель Нейронной сети для предсказания абсолютной температуры на поверхности звезды.

Базовая модель была построена с параметрами:

- n_in_neurons = 15
- n_hidden_neurons_1 = 12
- n_hidden_neurons_2 = 8
- n_out_neurons = 1
- optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)
- loss = nn.MSELoss()
- batch_size = 40
- num_epochs < 2000
- выходная функция после первого и второго скрытого слоя - ReLU

Данная модель оказалась недостаточно эффективна и легко переобучалась. Метрика RMSE получилась > 5 тыс, что нас не удовлетворяло, так ка согласно критериям заказчика, метрика RMSE не должна превышать 4500, потребовалось улучшение сети.

Улучшенная модель

Для улучшения нейронной сети попробовали методы Batch Normalization и Dropout, а также подбор оптимального количества эпох обучения, а также определили лучший оптимизатор
- n_in_neurons = 15
- n_hidden_neurons_1 = 12
- n_hidden_neurons_2 = 8
- n_out_neurons = 1
- optimizer = torch.optim.NAdam(net.parameters(), lr=1e-2)
- loss = nn.MSELoss()
- batch_size = 40
- num_epochs < 2000
- bn1 = nn.BatchNorm1d(n_hidden_neurons_1)
- dp1 = nn.Dropout(p=0.5)
- bn2 = nn.BatchNorm1d(n_hidden_neurons_2)
- выходная функция после первого и второго скрытого слоя - ReLU

Данную модель можно считать эффективной. Метрика RMSE получилась близка к 4000.

Сравнивая два графика, можно явно увидеть как плохо обучалась базовая модель (как много делала ошибок) и насколько лучше стала предсказывать после улучшения. <br />


## Стек технологий:

`pandas`, `matplotlib`, `numpy`, `seaborn`, `PyTorch`, `scikit-learn`, `phik`

## Статус проекта:

Завершен.
