# Классификация токсичных комментариев

Интернет-магазин «Викишоп» запускает новый сервис. 

Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75. 

Данные находятся в файле /datasets/toxic_comments.csv. 
Столбец text в нём содержит текст комментария, а toxic — целевой признак.

Алгоритм решения:
- Загрузите и подготовьте данные.
- Обучите разные модели.
- Сделайте выводы.

![Распространенные слова в токсичных английских комментариях](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/18_comments/18_toxic_comments.png)

![Распространенные слова в нейтральных английских комментариях](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/18_comments/18_neutral_comments.png)

Содержание

1.  Подготовка
    - 1.1  Загрузка библиотек
    - 1.2  Загрузка датасета
    - 1.3  Подготовка признаков перед обучением
    - 1.4  Изменение баланса классов
        - 1.4.1  Изменение весов классов
        - 1.4.2  Ресемплирование с уменьшением класса 0
2.  Обучение
    - 2.1  LogisticRegression
    - 2.2  SGDClassifier
3.  Выводы


## Цель исследования:

На основе собранных данных с разметкой о токсичности правок нужно обучить модель классифицировать комментарии на позитивные и негативные со значением метрики качества F1 не меньше 0.75. Построить модель для такого предсказания, используя полученные знания о машинном обучении для текстов.


## Ход исследования:

Шаг 1. Загрузим данные и выполним поиск лучшего способа балансировки и сравним качество.

Шаг 2. Проанализируем данные и проведем очистку текстов.

Шаг 3. Подготовим признаки перед обучением, с помощью библиотеку spacy проведем лемматизацию

Шаг 3. Обучим разные модели с различными гиперпараметрами. Сделаем тестовую выборку размером 20% от исходных данных.

Шаг 4. Проверим данные на тестовой выборке, сформируем матрицу ошибок и сделаем выводы.



## Итог исследования:

Загружены данные. Проведена предобработка данных. Проанализированы данные.

В отзывах присутствует дисбаланс классов: соотношение положительных комментариев к отрицательным было равно 1:9

Всего комментариев ~ 160 тыс.

Классы несбалансированы. Проведен поиск лучшего способа балансировки.

Изменение весов в модели обучения оказалось лучшим.


**Выбор признаков для моделей**
Лемматизация проводилась с помощью библиотеки SpaCy - она медленнее, но дружелюбнее, не нужна предварительная токенизация и учет постегов. 

Cравнение RSME, после проведения кроссвалидацию на обучающей выборке по каждой из рассматриваемых моделей:

|   | F1 |
|--|--|
|LogisticRegression| 78.632 |
|SGDClassifier| 76.563 |
|DecisionTreeClassifier| 62.515 |
|CatBoostClassifier| 71.866 |

На тестировании оптимальными показателями F1 и AUC-ROC обладает классификатор, где учтен вес классов. В обучении использован именно этот метод балансирования.
CatBoostClassifier может показать себя очень хорошо при долгом обучении на данных. В ходе тестов выяснилось, что данный классификатор тратит очень много времени на обучение, поэтому для сокращения сроков ему были выданы маленькие значения максимального количества построенных деревьев. От дальнейшего исследования DecisionTreeClassifier также было принято решение отказаться.

В ходе работы над проектом был обработан датасет с комментариями на английском языке, где нужно было определить, негативный отзыв или нет.
Подготовленны данные обучения на моделях. Для приведения текстов к векторному виду были пременены методы:

- очистка и лемматизация
- TF - IDF векторизация

Поделены данные на обучающую и тестовою выборку.
Обучены модели и выбраны лучшие из них на валидационной выборке.
Показаны параметры качества моделей, а также графики для наглядности.

Исходные данные обладают большим количеством признаков. Созданных столбцов больше, чем записей данных. Так как TF-IDF превращают текст в численные значения, лучшими моделями стали LogisticRegression и SGDClassifier.

На тестовой выбоке по метрике F1 лучше всего себя показала Логистическая регрессия. Данная модель обладает лучшими показателями по матрице ошибок. Это говорит нам, что токсичные комментарии находятся лучше.

![Матрица ошибок](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/18_comments/18_confusion_matrix.png)

На тестовой выборке модель логистическая регрессия показала - **0.793**, что подходит под требования задачи.

В сравнении участвовали модели логистической регрессии и модель градиентного бустинга SGD. Лучше всего проявила себя модель Логистической регрессии с гиперпараметрами

- 'C': 10, 
- 'class_weight': {'balanced'}.

TfidfVectorizer
- ngram_range=(1,3),
- min_df=3, 
- max_df=0.9,
- use_idf=1,
- smooth_idf=1,
- sublinear_tf=1.

![Логистическая регрессия](https://github.com/vadimprimakov/Yandex_practicum_DS_Plus/blob/main/18_comments/18_lr_model.png)

Требование о значении метрики F1 (более 75) выполнено.

## Стек технологий:

`pandas`, `matplotlib`, `numpy`, `seaborn`, `scikit-learn`, `LogisticRegression`, `spacy`, `nltk`, `SGDClassifier`, `wordcloud`

## Статус проекта:

Завершен.
